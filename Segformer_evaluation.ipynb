{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# Load the model\n",
    "model_directory = './scripts/segformer_output'\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict, load_from_disk\n",
    "import os\n",
    "\n",
    "def load_batches(split_name, directory):\n",
    "    batches = []\n",
    "    batch_num = 0\n",
    "    while True:\n",
    "        batch_dir = os.path.join(directory, f\"{split_name}_batch_{batch_num}.arrow\")\n",
    "        if not os.path.exists(batch_dir):\n",
    "            break\n",
    "        batch_dataset = load_from_disk(batch_dir)\n",
    "        batches.append(batch_dataset)\n",
    "        batch_num += 1\n",
    "    return concatenate_datasets(batches) if batches else None\n",
    "\n",
    "# Load each split\n",
    "dataset_path = './gta_dataset'\n",
    "\n",
    "train_dataset = load_batches('train', dataset_path)\n",
    "validation_dataset = load_batches('validation', dataset_path)\n",
    "test_dataset = load_batches('test', dataset_path)\n",
    "\n",
    "# Create a DatasetDict\n",
    "hf_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "gta_train_ds = hf_datasets[\"train\"]\n",
    "gta_test_ds = hf_datasets[\"test\"].train_test_split(test_size=0.1)['test']\n",
    "gta_val_ds = hf_datasets[\"validation\"].train_test_split(test_size=0.1)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/huggingface_hub/file_download.py:671: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "processor = SegformerImageProcessor()\n",
    "\n",
    "\n",
    "import json\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"cityscapes-id2label.json\"\n",
    "id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type=\"dataset\")), \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "id2label[19] = 'ignore'\n",
    "label2id['ignore'] = 19\n",
    "num_labels = len(id2label)\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [Image.fromarray(np.array(x, dtype=np.uint8)) for x in example_batch['image']]\n",
    "    labels = [Image.fromarray(np.array(x, dtype=np.uint8), mode='L') for x in example_batch['mask']]\n",
    "    \n",
    "    # Ensure labels are within the expected range\n",
    "    labels = [Image.fromarray(np.minimum(np.array(label), num_labels - 1), mode='L') for label in labels]\n",
    "    \n",
    "    inputs = processor(images=images, segmentation_maps=labels, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  with torch.no_grad():\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    # scale the logits to the size of the label\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    metrics = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=len(id2label),\n",
    "        ignore_index=19,\n",
    "        reduce_labels=processor.do_reduce_labels,\n",
    "    )\n",
    "    \n",
    "    # add per category metrics as individual key-value pairs\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "    \n",
    "    return metrics\n",
    "  \n",
    "gta_test_ds.set_transform(val_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Assuming evaluation doesn't require gradient updates\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir='./segformer_evaluation/sgf-v0-gta',  # Directory to store evaluation results\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    eval_steps=10,\n",
    "    logging_steps=5,\n",
    "    per_device_eval_batch_size=10,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=eval_args,\n",
    "    eval_dataset=gta_test_ds,\n",
    "    compute_metrics=compute_metrics  # Your metrics function as defined earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 07:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "/home/gcasadella/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5304863452911377, 'eval_mean_iou': 0.3863717727599142, 'eval_mean_accuracy': 0.4594820622645841, 'eval_overall_accuracy': 0.877796907688061, 'eval_accuracy_road': 0.9489809431222332, 'eval_accuracy_sidewalk': 0.8455630469421747, 'eval_accuracy_building': 0.9184319410853448, 'eval_accuracy_wall': 0.44873866548323804, 'eval_accuracy_fence': 0.2258698878655819, 'eval_accuracy_pole': 0.20655266367158562, 'eval_accuracy_traffic light': 0.0, 'eval_accuracy_traffic sign': 0.0, 'eval_accuracy_vegetation': 0.8701828218735161, 'eval_accuracy_terrain': 0.48447198018374665, 'eval_accuracy_sky': 0.9759494728206349, 'eval_accuracy_person': 0.46963642497888913, 'eval_accuracy_rider': 0.0, 'eval_accuracy_car': 0.9183919255986837, 'eval_accuracy_truck': 0.7639999478392405, 'eval_accuracy_bus': 0.6533894615622279, 'eval_accuracy_train': 0.0, 'eval_accuracy_motorcycle': 0.0, 'eval_accuracy_bicycle': 0.0, 'eval_accuracy_ignore': nan, 'eval_iou_road': 0.9180418984751986, 'eval_iou_sidewalk': 0.7313570464885094, 'eval_iou_building': 0.8009566177938597, 'eval_iou_wall': 0.37947135831448287, 'eval_iou_fence': 0.2024631043010466, 'eval_iou_pole': 0.17764894431211686, 'eval_iou_traffic light': 0.0, 'eval_iou_traffic sign': 0.0, 'eval_iou_vegetation': 0.7098098136862394, 'eval_iou_terrain': 0.4269937162526332, 'eval_iou_sky': 0.9295866001833509, 'eval_iou_person': 0.35261619649221454, 'eval_iou_rider': 0.0, 'eval_iou_car': 0.8107652652247773, 'eval_iou_truck': 0.6620217799686436, 'eval_iou_bus': 0.6257031137052117, 'eval_iou_train': 0.0, 'eval_iou_motorcycle': 0.0, 'eval_iou_bicycle': 0.0, 'eval_iou_ignore': 0.0, 'eval_runtime': 686.5265, 'eval_samples_per_second': 0.897, 'eval_steps_per_second': 0.012}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------------+\n",
      "|           Metric            |        Value        |\n",
      "+-----------------------------+---------------------+\n",
      "|          eval_loss          | 0.5304863452911377  |\n",
      "|        eval_mean_iou        | 0.3863717727599142  |\n",
      "|     eval_mean_accuracy      | 0.4594820622645841  |\n",
      "|    eval_overall_accuracy    |  0.877796907688061  |\n",
      "|     eval_accuracy_road      | 0.9489809431222332  |\n",
      "|   eval_accuracy_sidewalk    | 0.8455630469421747  |\n",
      "|   eval_accuracy_building    | 0.9184319410853448  |\n",
      "|     eval_accuracy_wall      | 0.44873866548323804 |\n",
      "|     eval_accuracy_fence     | 0.2258698878655819  |\n",
      "|     eval_accuracy_pole      | 0.20655266367158562 |\n",
      "| eval_accuracy_traffic light |         0.0         |\n",
      "| eval_accuracy_traffic sign  |         0.0         |\n",
      "|  eval_accuracy_vegetation   | 0.8701828218735161  |\n",
      "|    eval_accuracy_terrain    | 0.48447198018374665 |\n",
      "|      eval_accuracy_sky      | 0.9759494728206349  |\n",
      "|    eval_accuracy_person     | 0.46963642497888913 |\n",
      "|     eval_accuracy_rider     |         0.0         |\n",
      "|      eval_accuracy_car      | 0.9183919255986837  |\n",
      "|     eval_accuracy_truck     | 0.7639999478392405  |\n",
      "|      eval_accuracy_bus      | 0.6533894615622279  |\n",
      "|     eval_accuracy_train     |         0.0         |\n",
      "|  eval_accuracy_motorcycle   |         0.0         |\n",
      "|    eval_accuracy_bicycle    |         0.0         |\n",
      "|    eval_accuracy_ignore     |         nan         |\n",
      "|        eval_iou_road        | 0.9180418984751986  |\n",
      "|      eval_iou_sidewalk      | 0.7313570464885094  |\n",
      "|      eval_iou_building      | 0.8009566177938597  |\n",
      "|        eval_iou_wall        | 0.37947135831448287 |\n",
      "|       eval_iou_fence        | 0.2024631043010466  |\n",
      "|        eval_iou_pole        | 0.17764894431211686 |\n",
      "|   eval_iou_traffic light    |         0.0         |\n",
      "|    eval_iou_traffic sign    |         0.0         |\n",
      "|     eval_iou_vegetation     | 0.7098098136862394  |\n",
      "|      eval_iou_terrain       | 0.4269937162526332  |\n",
      "|        eval_iou_sky         | 0.9295866001833509  |\n",
      "|       eval_iou_person       | 0.35261619649221454 |\n",
      "|       eval_iou_rider        |         0.0         |\n",
      "|        eval_iou_car         | 0.8107652652247773  |\n",
      "|       eval_iou_truck        | 0.6620217799686436  |\n",
      "|        eval_iou_bus         | 0.6257031137052117  |\n",
      "|       eval_iou_train        |         0.0         |\n",
      "|     eval_iou_motorcycle     |         0.0         |\n",
      "|      eval_iou_bicycle       |         0.0         |\n",
      "|       eval_iou_ignore       |         0.0         |\n",
      "|        eval_runtime         |      686.5265       |\n",
      "|   eval_samples_per_second   |        0.897        |\n",
      "|    eval_steps_per_second    |        0.012        |\n",
      "+-----------------------------+---------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Formatting the output in a pretty table using Python's tabulate library\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "output = {\n",
    "    'eval_loss': 0.5304863452911377,\n",
    "    'eval_mean_iou': 0.3863717727599142,\n",
    "    'eval_mean_accuracy': 0.4594820622645841,\n",
    "    'eval_overall_accuracy': 0.877796907688061,\n",
    "    'eval_accuracy_road': 0.9489809431222332,\n",
    "    'eval_accuracy_sidewalk': 0.8455630469421747,\n",
    "    'eval_accuracy_building': 0.9184319410853448,\n",
    "    'eval_accuracy_wall': 0.44873866548323804,\n",
    "    'eval_accuracy_fence': 0.2258698878655819,\n",
    "    'eval_accuracy_pole': 0.20655266367158562,\n",
    "    'eval_accuracy_traffic light': 0.0,\n",
    "    'eval_accuracy_traffic sign': 0.0,\n",
    "    'eval_accuracy_vegetation': 0.8701828218735161,\n",
    "    'eval_accuracy_terrain': 0.48447198018374665,\n",
    "    'eval_accuracy_sky': 0.9759494728206349,\n",
    "    'eval_accuracy_person': 0.46963642497888913,\n",
    "    'eval_accuracy_rider': 0.0,\n",
    "    'eval_accuracy_car': 0.9183919255986837,\n",
    "    'eval_accuracy_truck': 0.7639999478392405,\n",
    "    'eval_accuracy_bus': 0.6533894615622279,\n",
    "    'eval_accuracy_train': 0.0,\n",
    "    'eval_accuracy_motorcycle': 0.0,\n",
    "    'eval_accuracy_bicycle': 0.0,\n",
    "    'eval_accuracy_ignore': 'nan',\n",
    "    'eval_iou_road': 0.9180418984751986,\n",
    "    'eval_iou_sidewalk': 0.7313570464885094,\n",
    "    'eval_iou_building': 0.8009566177938597,\n",
    "    'eval_iou_wall': 0.37947135831448287,\n",
    "    'eval_iou_fence': 0.2024631043010466,\n",
    "    'eval_iou_pole': 0.17764894431211686,\n",
    "    'eval_iou_traffic light': 0.0,\n",
    "    'eval_iou_traffic sign': 0.0,\n",
    "    'eval_iou_vegetation': 0.7098098136862394,\n",
    "    'eval_iou_terrain': 0.4269937162526332,\n",
    "    'eval_iou_sky': 0.9295866001833509,\n",
    "    'eval_iou_person': 0.35261619649221454,\n",
    "    'eval_iou_rider': 0.0,\n",
    "    'eval_iou_car': 0.8107652652247773,\n",
    "    'eval_iou_truck': 0.6620217799686436,\n",
    "    'eval_iou_bus': 0.6257031137052117,\n",
    "    'eval_iou_train': 0.0,\n",
    "    'eval_iou_motorcycle': 0.0,\n",
    "    'eval_iou_bicycle': 0.0,\n",
    "    'eval_iou_ignore': 0.0,\n",
    "    'eval_runtime': 686.5265,\n",
    "    'eval_samples_per_second': 0.897,\n",
    "    'eval_steps_per_second': 0.012\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a list of lists for tabulate\n",
    "data = [[key, value] for key, value in output.items()]\n",
    "\n",
    "# Create the table\n",
    "table = tabulate(data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\")\n",
    "\n",
    "print(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugginface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
