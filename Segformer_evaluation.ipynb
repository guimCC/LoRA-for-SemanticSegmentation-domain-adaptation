{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# Load the model\n",
    "model_directory = './scripts/segformer_output'\n",
    "model_directory = 'guimCC/segformer-v0-gta'\n",
    "original_model = SegformerForSemanticSegmentation.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "model_id = \"guimCC/segformer-v0-gta-cityscapes\"\n",
    "#model_id = \"./scripts/segformer-gta-cityscapes-lora\"\n",
    "\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "\n",
    "checkpoint_dir = \"guimCC/segformer-v0-gta\"\n",
    "\n",
    "image_processor = SegformerImageProcessor()\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(checkpoint_dir)\n",
    "\n",
    "config = PeftConfig.from_pretrained(model_id)\n",
    "\n",
    "# Load the Lora model\n",
    "lora_model = PeftModel.from_pretrained(model, model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/guimCC/segformer-v0-gta-cityscapes/commit/2b21925b822c9b80383960960b0082724d997407', commit_message='Upload model', commit_description='', oid='2b21925b822c9b80383960960b0082724d997407', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.push_to_hub(\"guimCC/segformer-v0-gta-cityscapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict, load_from_disk\n",
    "import os\n",
    "\n",
    "def load_batches(split_name, directory):\n",
    "    batches = []\n",
    "    batch_num = 0\n",
    "    while True:\n",
    "        batch_dir = os.path.join(directory, f\"{split_name}_batch_{batch_num}.arrow\")\n",
    "        if not os.path.exists(batch_dir):\n",
    "            break\n",
    "        batch_dataset = load_from_disk(batch_dir)\n",
    "        batches.append(batch_dataset)\n",
    "        batch_num += 1\n",
    "    return concatenate_datasets(batches) if batches else None\n",
    "\n",
    "# Load each split\n",
    "dataset_path = './gta_dataset'\n",
    "\n",
    "train_dataset = load_batches('train', dataset_path)\n",
    "validation_dataset = load_batches('validation', dataset_path)\n",
    "test_dataset = load_batches('test', dataset_path)\n",
    "\n",
    "# Create a DatasetDict\n",
    "hf_datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "gta_train_ds = hf_datasets[\"train\"]\n",
    "gta_test_ds = hf_datasets[\"test\"].train_test_split(test_size=0.1)['test']\n",
    "gta_val_ds = hf_datasets[\"validation\"].train_test_split(test_size=0.1)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict, load_from_disk\n",
    "\n",
    "# Load the dataset from disk\n",
    "loaded_dataset = load_from_disk(\"./cityscapes_train_1000_dataset_v3\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Prepare train and test splits\n",
    "\n",
    "loaded_dataset = loaded_dataset.train_test_split(test_size=0.1)\n",
    "cty_test_ds = loaded_dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/huggingface_hub/file_download.py:671: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "processor = SegformerImageProcessor()\n",
    "\n",
    "\n",
    "import json\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"cityscapes-id2label.json\"\n",
    "id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type=\"dataset\")), \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "id2label[19] = 'ignore'\n",
    "label2id['ignore'] = 19\n",
    "num_labels = len(id2label)\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [Image.fromarray(np.array(x, dtype=np.uint8)) for x in example_batch['image']]\n",
    "    labels = [Image.fromarray(np.array(x, dtype=np.uint8), mode='L') for x in example_batch['mask']]\n",
    "    \n",
    "    # Ensure labels are within the expected range\n",
    "    labels = [Image.fromarray(np.minimum(np.array(label), num_labels - 1), mode='L') for label in labels]\n",
    "    \n",
    "    inputs = processor(images=images, segmentation_maps=labels, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  with torch.no_grad():\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    # scale the logits to the size of the label\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    metrics = metric.compute(\n",
    "        predictions=pred_labels,\n",
    "        references=labels,\n",
    "        num_labels=len(id2label),\n",
    "        ignore_index=19,\n",
    "        reduce_labels=processor.do_reduce_labels,\n",
    "    )\n",
    "    \n",
    "    # add per category metrics as individual key-value pairs\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "    \n",
    "    return metrics\n",
    "  \n",
    "gta_test_ds.set_transform(val_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"cityscapes-id2label.json\"\n",
    "id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type=\"dataset\")), \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "id2label[19] = 'ignore'\n",
    "label2id['ignore'] = 19\n",
    "num_labels = len(id2label)\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "from torchvision.transforms import ColorJitter\n",
    "\n",
    "# Transofrms the color properities\n",
    "jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def handle_grayscale_image(image):\n",
    "    np_image = np.array(image)\n",
    "    if np_image.ndim == 2:\n",
    "        tiled_image = np.tile(np.expand_dims(np_image, -1), 3)\n",
    "        return Image.fromarray(tiled_image)\n",
    "    else:\n",
    "        return Image.fromarray(np_image)\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    images = [handle_grayscale_image(x) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    with torch.no_grad(): # Don't want to store the gradients while computing this metric since it's validation\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        # scale the logits to the size of the label\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        # currently using _compute instead of compute\n",
    "        # see this issue for more info: https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n",
    "        metrics = metric._compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=len(id2label),\n",
    "            ignore_index=0,\n",
    "            reduce_labels=image_processor.do_reduce_labels,\n",
    "        )\n",
    "\n",
    "        # add per category metrics as individual key-value pairs\n",
    "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "        return metrics\n",
    "  \n",
    "cty_test_ds.set_transform(val_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Assuming evaluation doesn't require gradient updates\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir='./segformer_evaluation/sgf-v0-cty',  # Directory to store evaluation results\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    eval_steps=10,\n",
    "    logging_steps=5,\n",
    "    per_device_eval_batch_size=10,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_model,\n",
    "    args=eval_args,\n",
    "    eval_dataset=cty_test_ds,\n",
    "    compute_metrics=compute_metrics  # Your metrics function as defined earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2160677909851074, 'eval_mean_iou': 0.08249961911508377, 'eval_mean_accuracy': 0.3430836199348098, 'eval_overall_accuracy': 0.7057258167711694, 'eval_accuracy_road': nan, 'eval_accuracy_sidewalk': 0.452280847430867, 'eval_accuracy_building': 0.8751869702509556, 'eval_accuracy_wall': 0.33387868724360226, 'eval_accuracy_fence': 0.23689513284076605, 'eval_accuracy_pole': 0.149771875716871, 'eval_accuracy_traffic light': 0.0, 'eval_accuracy_traffic sign': 0.0, 'eval_accuracy_vegetation': 0.9201750423182221, 'eval_accuracy_terrain': 0.8118086934949409, 'eval_accuracy_sky': 0.9956422699811825, 'eval_accuracy_person': 0.3508328122335285, 'eval_accuracy_rider': 0.0, 'eval_accuracy_car': 0.7460295161214794, 'eval_accuracy_truck': 0.3030033111941599, 'eval_accuracy_bus': 0.0, 'eval_accuracy_train': 0.0, 'eval_accuracy_motorcycle': 0.0, 'eval_accuracy_bicycle': 0.0, 'eval_accuracy_ignore': nan, 'eval_iou_road': 0.0, 'eval_iou_sidewalk': 0.022881098458391723, 'eval_iou_building': 0.0428390443622827, 'eval_iou_wall': 0.07388853763057353, 'eval_iou_fence': 0.19313600971892428, 'eval_iou_pole': 0.09649554964364306, 'eval_iou_traffic light': 0.0, 'eval_iou_traffic sign': 0.0, 'eval_iou_vegetation': 0.0716031128915547, 'eval_iou_terrain': 0.39704087858450277, 'eval_iou_sky': 0.43693614182859686, 'eval_iou_person': 0.054200625307384245, 'eval_iou_rider': 0.0, 'eval_iou_car': 0.12410920814506754, 'eval_iou_truck': 0.13686217573075377, 'eval_iou_bus': 0.0, 'eval_iou_train': 0.0, 'eval_iou_motorcycle': 0.0, 'eval_iou_bicycle': 0.0, 'eval_iou_ignore': 0.0, 'eval_runtime': 15.0928, 'eval_samples_per_second': 6.626, 'eval_steps_per_second': 0.133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Assuming evaluation doesn't require gradient updates\n",
    "lora_eval_args = TrainingArguments(\n",
    "    output_dir='./segformer_evaluation/sgf-v0-lora-cty',  # Directory to store evaluation results\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    eval_steps=10,\n",
    "    logging_steps=5,\n",
    "    per_device_eval_batch_size=10,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"]\n",
    "\n",
    ")\n",
    "\n",
    "# Compute Metrics Issue: https://github.com/huggingface/transformers/issues/29186\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=lora_eval_args,\n",
    "    eval_dataset=cty_test_ds,\n",
    "    compute_metrics=compute_metrics  # Your metrics function as defined earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/gcasadella/miniconda3/envs/hugginface/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16964639723300934, 'eval_mean_iou': 0.23273853558468585, 'eval_mean_accuracy': 0.8557465871805577, 'eval_overall_accuracy': 0.922382745940558, 'eval_accuracy_road': nan, 'eval_accuracy_sidewalk': 0.8975153645087158, 'eval_accuracy_building': 0.9098147840378188, 'eval_accuracy_wall': 0.8705801914436413, 'eval_accuracy_fence': 0.8380793262853692, 'eval_accuracy_pole': 0.7568246119338312, 'eval_accuracy_traffic light': 0.789844189975596, 'eval_accuracy_traffic sign': 0.7714963744232037, 'eval_accuracy_vegetation': 0.9276372008469087, 'eval_accuracy_terrain': 0.9637375294597132, 'eval_accuracy_sky': 0.9979383652044556, 'eval_accuracy_person': 0.7645671081803195, 'eval_accuracy_rider': 0.6194160219615673, 'eval_accuracy_car': 0.9761392740201217, 'eval_accuracy_truck': 0.702689619115853, 'eval_accuracy_bus': 0.9686170212765958, 'eval_accuracy_train': 0.8235132158590308, 'eval_accuracy_motorcycle': 0.9681533440864248, 'eval_accuracy_bicycle': 0.8568750266308748, 'eval_accuracy_ignore': nan, 'eval_iou_road': 0.0, 'eval_iou_sidewalk': 0.13305125444486632, 'eval_iou_building': 0.05004134800803356, 'eval_iou_wall': 0.15970041613846794, 'eval_iou_fence': 0.3285951715453578, 'eval_iou_pole': 0.08824971764845747, 'eval_iou_traffic light': 0.2151458594329251, 'eval_iou_traffic sign': 0.16679112773125532, 'eval_iou_vegetation': 0.088245352649776, 'eval_iou_terrain': 0.4874015098830665, 'eval_iou_sky': 0.4333834831977473, 'eval_iou_person': 0.07837338585613725, 'eval_iou_rider': 0.11151547827649728, 'eval_iou_car': 0.14361598951923962, 'eval_iou_truck': 0.3716916584726319, 'eval_iou_bus': 0.2656261395959449, 'eval_iou_train': 0.6419832582099163, 'eval_iou_motorcycle': 0.4894189927184466, 'eval_iou_bicycle': 0.16920203278026452, 'eval_iou_ignore': nan, 'eval_runtime': 15.089, 'eval_samples_per_second': 6.627, 'eval_steps_per_second': 0.133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcasadella/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/home/gcasadella/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    }
   ],
   "source": [
    "lora_eval_results = lora_trainer.evaluate()\n",
    "print(lora_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------------+\n",
      "|           Metric            |        Value        |\n",
      "+-----------------------------+---------------------+\n",
      "|          eval_loss          | 0.5304863452911377  |\n",
      "|        eval_mean_iou        | 0.3863717727599142  |\n",
      "|     eval_mean_accuracy      | 0.4594820622645841  |\n",
      "|    eval_overall_accuracy    |  0.877796907688061  |\n",
      "|     eval_accuracy_road      | 0.9489809431222332  |\n",
      "|   eval_accuracy_sidewalk    | 0.8455630469421747  |\n",
      "|   eval_accuracy_building    | 0.9184319410853448  |\n",
      "|     eval_accuracy_wall      | 0.44873866548323804 |\n",
      "|     eval_accuracy_fence     | 0.2258698878655819  |\n",
      "|     eval_accuracy_pole      | 0.20655266367158562 |\n",
      "| eval_accuracy_traffic light |         0.0         |\n",
      "| eval_accuracy_traffic sign  |         0.0         |\n",
      "|  eval_accuracy_vegetation   | 0.8701828218735161  |\n",
      "|    eval_accuracy_terrain    | 0.48447198018374665 |\n",
      "|      eval_accuracy_sky      | 0.9759494728206349  |\n",
      "|    eval_accuracy_person     | 0.46963642497888913 |\n",
      "|     eval_accuracy_rider     |         0.0         |\n",
      "|      eval_accuracy_car      | 0.9183919255986837  |\n",
      "|     eval_accuracy_truck     | 0.7639999478392405  |\n",
      "|      eval_accuracy_bus      | 0.6533894615622279  |\n",
      "|     eval_accuracy_train     |         0.0         |\n",
      "|  eval_accuracy_motorcycle   |         0.0         |\n",
      "|    eval_accuracy_bicycle    |         0.0         |\n",
      "|    eval_accuracy_ignore     |         nan         |\n",
      "|        eval_iou_road        | 0.9180418984751986  |\n",
      "|      eval_iou_sidewalk      | 0.7313570464885094  |\n",
      "|      eval_iou_building      | 0.8009566177938597  |\n",
      "|        eval_iou_wall        | 0.37947135831448287 |\n",
      "|       eval_iou_fence        | 0.2024631043010466  |\n",
      "|        eval_iou_pole        | 0.17764894431211686 |\n",
      "|   eval_iou_traffic light    |         0.0         |\n",
      "|    eval_iou_traffic sign    |         0.0         |\n",
      "|     eval_iou_vegetation     | 0.7098098136862394  |\n",
      "|      eval_iou_terrain       | 0.4269937162526332  |\n",
      "|        eval_iou_sky         | 0.9295866001833509  |\n",
      "|       eval_iou_person       | 0.35261619649221454 |\n",
      "|       eval_iou_rider        |         0.0         |\n",
      "|        eval_iou_car         | 0.8107652652247773  |\n",
      "|       eval_iou_truck        | 0.6620217799686436  |\n",
      "|        eval_iou_bus         | 0.6257031137052117  |\n",
      "|       eval_iou_train        |         0.0         |\n",
      "|     eval_iou_motorcycle     |         0.0         |\n",
      "|      eval_iou_bicycle       |         0.0         |\n",
      "|       eval_iou_ignore       |         0.0         |\n",
      "|        eval_runtime         |      686.5265       |\n",
      "|   eval_samples_per_second   |        0.897        |\n",
      "|    eval_steps_per_second    |        0.012        |\n",
      "+-----------------------------+---------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Formatting the output in a pretty table using Python's tabulate library\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "output = {\n",
    "    'eval_loss': 0.5304863452911377,\n",
    "    'eval_mean_iou': 0.3863717727599142,\n",
    "    'eval_mean_accuracy': 0.4594820622645841,\n",
    "    'eval_overall_accuracy': 0.877796907688061,\n",
    "    'eval_accuracy_road': 0.9489809431222332,\n",
    "    'eval_accuracy_sidewalk': 0.8455630469421747,\n",
    "    'eval_accuracy_building': 0.9184319410853448,\n",
    "    'eval_accuracy_wall': 0.44873866548323804,\n",
    "    'eval_accuracy_fence': 0.2258698878655819,\n",
    "    'eval_accuracy_pole': 0.20655266367158562,\n",
    "    'eval_accuracy_traffic light': 0.0,\n",
    "    'eval_accuracy_traffic sign': 0.0,\n",
    "    'eval_accuracy_vegetation': 0.8701828218735161,\n",
    "    'eval_accuracy_terrain': 0.48447198018374665,\n",
    "    'eval_accuracy_sky': 0.9759494728206349,\n",
    "    'eval_accuracy_person': 0.46963642497888913,\n",
    "    'eval_accuracy_rider': 0.0,\n",
    "    'eval_accuracy_car': 0.9183919255986837,\n",
    "    'eval_accuracy_truck': 0.7639999478392405,\n",
    "    'eval_accuracy_bus': 0.6533894615622279,\n",
    "    'eval_accuracy_train': 0.0,\n",
    "    'eval_accuracy_motorcycle': 0.0,\n",
    "    'eval_accuracy_bicycle': 0.0,\n",
    "    'eval_accuracy_ignore': 'nan',\n",
    "    'eval_iou_road': 0.9180418984751986,\n",
    "    'eval_iou_sidewalk': 0.7313570464885094,\n",
    "    'eval_iou_building': 0.8009566177938597,\n",
    "    'eval_iou_wall': 0.37947135831448287,\n",
    "    'eval_iou_fence': 0.2024631043010466,\n",
    "    'eval_iou_pole': 0.17764894431211686,\n",
    "    'eval_iou_traffic light': 0.0,\n",
    "    'eval_iou_traffic sign': 0.0,\n",
    "    'eval_iou_vegetation': 0.7098098136862394,\n",
    "    'eval_iou_terrain': 0.4269937162526332,\n",
    "    'eval_iou_sky': 0.9295866001833509,\n",
    "    'eval_iou_person': 0.35261619649221454,\n",
    "    'eval_iou_rider': 0.0,\n",
    "    'eval_iou_car': 0.8107652652247773,\n",
    "    'eval_iou_truck': 0.6620217799686436,\n",
    "    'eval_iou_bus': 0.6257031137052117,\n",
    "    'eval_iou_train': 0.0,\n",
    "    'eval_iou_motorcycle': 0.0,\n",
    "    'eval_iou_bicycle': 0.0,\n",
    "    'eval_iou_ignore': 0.0,\n",
    "    'eval_runtime': 686.5265,\n",
    "    'eval_samples_per_second': 0.897,\n",
    "    'eval_steps_per_second': 0.012\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a list of lists for tabulate\n",
    "data = [[key, value] for key, value in output.items()]\n",
    "\n",
    "# Create the table\n",
    "table = tabulate(data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\")\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----------------------+\n",
      "|           Metric            |        Value         |\n",
      "+-----------------------------+----------------------+\n",
      "|          eval_loss          |  1.146903395652771   |\n",
      "|        eval_mean_iou        | 0.08527295022108815  |\n",
      "|     eval_mean_accuracy      | 0.35031907385611705  |\n",
      "|    eval_overall_accuracy    |  0.6403262338725791  |\n",
      "|     eval_accuracy_road      |  0.5707251169399141  |\n",
      "|   eval_accuracy_sidewalk    |  0.372826855881155   |\n",
      "|   eval_accuracy_building    |  0.8886840766712605  |\n",
      "|     eval_accuracy_wall      |  0.3608147036150444  |\n",
      "|     eval_accuracy_fence     | 0.10439456945390266  |\n",
      "|     eval_accuracy_pole      | 0.09889556124805779  |\n",
      "| eval_accuracy_traffic light |         0.0          |\n",
      "| eval_accuracy_traffic sign  |         0.0          |\n",
      "|  eval_accuracy_vegetation   |  0.9053155791789973  |\n",
      "|    eval_accuracy_terrain    |  0.8172969812841195  |\n",
      "|      eval_accuracy_sky      |  0.9914449084746553  |\n",
      "|    eval_accuracy_person     | 0.10675872093023256  |\n",
      "|     eval_accuracy_rider     |         0.0          |\n",
      "|      eval_accuracy_car      |  0.7414439247994549  |\n",
      "|     eval_accuracy_truck     | 0.48972868217054266  |\n",
      "|      eval_accuracy_bus      | 0.20773272261888726  |\n",
      "|     eval_accuracy_train     |         0.0          |\n",
      "|  eval_accuracy_motorcycle   |         0.0          |\n",
      "|    eval_accuracy_bicycle    |         0.0          |\n",
      "|    eval_accuracy_ignore     |         nan          |\n",
      "|        eval_iou_road        |  0.1931597801565552  |\n",
      "|      eval_iou_sidewalk      | 0.01675527174811858  |\n",
      "|      eval_iou_building      | 0.037787175770186185 |\n",
      "|        eval_iou_wall        | 0.05374355627270035  |\n",
      "|       eval_iou_fence        | 0.07243608432947611  |\n",
      "|        eval_iou_pole        |  0.0641508748672036  |\n",
      "|   eval_iou_traffic light    |         0.0          |\n",
      "|    eval_iou_traffic sign    |         0.0          |\n",
      "|     eval_iou_vegetation     | 0.06478703055444684  |\n",
      "|      eval_iou_terrain       |  0.3191420114236002  |\n",
      "|        eval_iou_sky         |  0.5165666641106099  |\n",
      "|       eval_iou_person       | 0.009816369079439752 |\n",
      "|       eval_iou_rider        |         0.0          |\n",
      "|        eval_iou_car         |  0.1253018669789748  |\n",
      "|       eval_iou_truck        | 0.11226121723678366  |\n",
      "|        eval_iou_bus         | 0.11955110189366774  |\n",
      "|       eval_iou_train        |         0.0          |\n",
      "|     eval_iou_motorcycle     |         0.0          |\n",
      "|      eval_iou_bicycle       |         0.0          |\n",
      "|       eval_iou_ignore       |         0.0          |\n",
      "|        eval_runtime         |        22.695        |\n",
      "|   eval_samples_per_second   |        4.406         |\n",
      "|    eval_steps_per_second    |        0.088         |\n",
      "+-----------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Formatting the output in a pretty table using Python's tabulate library\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "output = {'eval_loss': 1.146903395652771, 'eval_mean_iou': 0.08527295022108815, 'eval_mean_accuracy': 0.35031907385611705, 'eval_overall_accuracy': 0.6403262338725791, 'eval_accuracy_road': 0.5707251169399141, 'eval_accuracy_sidewalk': 0.372826855881155, 'eval_accuracy_building': 0.8886840766712605, 'eval_accuracy_wall': 0.3608147036150444, 'eval_accuracy_fence': 0.10439456945390266, 'eval_accuracy_pole': 0.09889556124805779, 'eval_accuracy_traffic light': 0.0, 'eval_accuracy_traffic sign': 0.0, 'eval_accuracy_vegetation': 0.9053155791789973, 'eval_accuracy_terrain': 0.8172969812841195, 'eval_accuracy_sky': 0.9914449084746553, 'eval_accuracy_person': 0.10675872093023256, 'eval_accuracy_rider': 0.0, 'eval_accuracy_car': 0.7414439247994549, 'eval_accuracy_truck': 0.48972868217054266, 'eval_accuracy_bus': 0.20773272261888726, 'eval_accuracy_train': 0.0, 'eval_accuracy_motorcycle': 0.0, 'eval_accuracy_bicycle': 0.0, 'eval_accuracy_ignore': 'nan', 'eval_iou_road': 0.1931597801565552, 'eval_iou_sidewalk': 0.01675527174811858, 'eval_iou_building': 0.037787175770186185, 'eval_iou_wall': 0.05374355627270035, 'eval_iou_fence': 0.07243608432947611, 'eval_iou_pole': 0.0641508748672036, 'eval_iou_traffic light': 0.0, 'eval_iou_traffic sign': 0.0, 'eval_iou_vegetation': 0.06478703055444684, 'eval_iou_terrain': 0.3191420114236002, 'eval_iou_sky': 0.5165666641106099, 'eval_iou_person': 0.009816369079439752, 'eval_iou_rider': 0.0, 'eval_iou_car': 0.1253018669789748, 'eval_iou_truck': 0.11226121723678366, 'eval_iou_bus': 0.11955110189366774, 'eval_iou_train': 0.0, 'eval_iou_motorcycle': 0.0, 'eval_iou_bicycle': 0.0, 'eval_iou_ignore': 0.0, 'eval_runtime': 22.695, 'eval_samples_per_second': 4.406, 'eval_steps_per_second': 0.088}\n",
    "\n",
    "# Convert the dictionary to a list of lists for tabulate\n",
    "data = [[key, value] for key, value in output.items()]\n",
    "\n",
    "# Create the table\n",
    "table = tabulate(data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\")\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cityscapes LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------------------+\n",
      "|           Metric            |        Value        |\n",
      "+-----------------------------+---------------------+\n",
      "|          eval_loss          | 0.16964639723300934 |\n",
      "|        eval_mean_iou        | 0.23273853558468585 |\n",
      "|     eval_mean_accuracy      | 0.8557465871805577  |\n",
      "|    eval_overall_accuracy    |  0.922382745940558  |\n",
      "|     eval_accuracy_road      |         nan         |\n",
      "|   eval_accuracy_sidewalk    | 0.8975153645087158  |\n",
      "|   eval_accuracy_building    | 0.9098147840378188  |\n",
      "|     eval_accuracy_wall      | 0.8705801914436413  |\n",
      "|     eval_accuracy_fence     | 0.8380793262853692  |\n",
      "|     eval_accuracy_pole      | 0.7568246119338312  |\n",
      "| eval_accuracy_traffic light |  0.789844189975596  |\n",
      "| eval_accuracy_traffic sign  | 0.7714963744232037  |\n",
      "|  eval_accuracy_vegetation   | 0.9276372008469087  |\n",
      "|    eval_accuracy_terrain    | 0.9637375294597132  |\n",
      "|      eval_accuracy_sky      | 0.9979383652044556  |\n",
      "|    eval_accuracy_person     | 0.7645671081803195  |\n",
      "|     eval_accuracy_rider     | 0.6194160219615673  |\n",
      "|      eval_accuracy_car      | 0.9761392740201217  |\n",
      "|     eval_accuracy_truck     |  0.702689619115853  |\n",
      "|      eval_accuracy_bus      | 0.9686170212765958  |\n",
      "|     eval_accuracy_train     | 0.8235132158590308  |\n",
      "|  eval_accuracy_motorcycle   | 0.9681533440864248  |\n",
      "|    eval_accuracy_bicycle    | 0.8568750266308748  |\n",
      "|    eval_accuracy_ignore     |         nan         |\n",
      "|        eval_iou_road        |         0.0         |\n",
      "|      eval_iou_sidewalk      | 0.13305125444486632 |\n",
      "|      eval_iou_building      | 0.05004134800803356 |\n",
      "|        eval_iou_wall        | 0.15970041613846794 |\n",
      "|       eval_iou_fence        | 0.3285951715453578  |\n",
      "|        eval_iou_pole        | 0.08824971764845747 |\n",
      "|   eval_iou_traffic light    | 0.2151458594329251  |\n",
      "|    eval_iou_traffic sign    | 0.16679112773125532 |\n",
      "|     eval_iou_vegetation     |  0.088245352649776  |\n",
      "|      eval_iou_terrain       | 0.4874015098830665  |\n",
      "|        eval_iou_sky         | 0.4333834831977473  |\n",
      "|       eval_iou_person       | 0.07837338585613725 |\n",
      "|       eval_iou_rider        | 0.11151547827649728 |\n",
      "|        eval_iou_car         | 0.14361598951923962 |\n",
      "|       eval_iou_truck        | 0.3716916584726319  |\n",
      "|        eval_iou_bus         | 0.2656261395959449  |\n",
      "|       eval_iou_train        | 0.6419832582099163  |\n",
      "|     eval_iou_motorcycle     | 0.4894189927184466  |\n",
      "|      eval_iou_bicycle       | 0.16920203278026452 |\n",
      "|       eval_iou_ignore       |         nan         |\n",
      "|        eval_runtime         |       15.089        |\n",
      "|   eval_samples_per_second   |        6.627        |\n",
      "|    eval_steps_per_second    |        0.133        |\n",
      "+-----------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# Formatting the output in a pretty table using Python's tabulate library\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "output = {'eval_loss': 0.16964639723300934, 'eval_mean_iou': 0.23273853558468585, 'eval_mean_accuracy': 0.8557465871805577, 'eval_overall_accuracy': 0.922382745940558, 'eval_accuracy_road': 'nan', 'eval_accuracy_sidewalk': 0.8975153645087158, 'eval_accuracy_building': 0.9098147840378188, 'eval_accuracy_wall': 0.8705801914436413, 'eval_accuracy_fence': 0.8380793262853692, 'eval_accuracy_pole': 0.7568246119338312, 'eval_accuracy_traffic light': 0.789844189975596, 'eval_accuracy_traffic sign': 0.7714963744232037, 'eval_accuracy_vegetation': 0.9276372008469087, 'eval_accuracy_terrain': 0.9637375294597132, 'eval_accuracy_sky': 0.9979383652044556, 'eval_accuracy_person': 0.7645671081803195, 'eval_accuracy_rider': 0.6194160219615673, 'eval_accuracy_car': 0.9761392740201217, 'eval_accuracy_truck': 0.702689619115853, 'eval_accuracy_bus': 0.9686170212765958, 'eval_accuracy_train': 0.8235132158590308, 'eval_accuracy_motorcycle': 0.9681533440864248, 'eval_accuracy_bicycle': 0.8568750266308748, 'eval_accuracy_ignore': 'nan', 'eval_iou_road': 0.0, 'eval_iou_sidewalk': 0.13305125444486632, 'eval_iou_building': 0.05004134800803356, 'eval_iou_wall': 0.15970041613846794, 'eval_iou_fence': 0.3285951715453578, 'eval_iou_pole': 0.08824971764845747, 'eval_iou_traffic light': 0.2151458594329251, 'eval_iou_traffic sign': 0.16679112773125532, 'eval_iou_vegetation': 0.088245352649776, 'eval_iou_terrain': 0.4874015098830665, 'eval_iou_sky': 0.4333834831977473, 'eval_iou_person': 0.07837338585613725, 'eval_iou_rider': 0.11151547827649728, 'eval_iou_car': 0.14361598951923962, 'eval_iou_truck': 0.3716916584726319, 'eval_iou_bus': 0.2656261395959449, 'eval_iou_train': 0.6419832582099163, 'eval_iou_motorcycle': 0.4894189927184466, 'eval_iou_bicycle': 0.16920203278026452, 'eval_iou_ignore': 'nan', 'eval_runtime': 15.089, 'eval_samples_per_second': 6.627, 'eval_steps_per_second': 0.133}\n",
    "\n",
    "# Convert the dictionary to a list of lists for tabulate\n",
    "data = [[key, value] for key, value in output.items()]\n",
    "\n",
    "# Create the table\n",
    "table = tabulate(data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\")\n",
    "\n",
    "print(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugginface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
